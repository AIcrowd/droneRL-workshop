{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colab Setup\n",
    "---\n",
    "\n",
    "Make sure to select GPU in Runtime > Change runtime type > Hardware accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title << Setup Google Colab by running this cell {display-mode: \"form\"}\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/pacm/rl-workshop.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"rl-workshop/agents\" \"rl-workshop/env\" \"rl-workshop/helpers\" .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"rl-workshop/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PER and curiosity\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run env/env.py\n",
    "%run helpers/rl-helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.dqn import DQNAgent, ConvQNetworkFactory\n",
    "from agents.random import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WindowedGridView(DeliveryDrones(), radius=3)\n",
    "env.env_params.update({'n_drones': 5, 'pickup_reward': 1, 'discharge': 2, 'rgb_render_rescale': 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DQN with conv. Q-network\"\"\"\n",
    "dqn_agent_1 = DQNAgent(\n",
    "    env, ConvQNetworkFactory(env, conv_layers=[\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1}\n",
    "    ], dense_layers=[256]),\n",
    "    gamma=0.95, epsilon_start=1, epsilon_decay=0.99, epsilon_end=0.01, memory_size=10000, batch_size=64, target_update_interval=5)\n",
    "\n",
    "dqn_agent_2 = DQNAgent(\n",
    "    env, ConvQNetworkFactory(env, conv_layers=[\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1}\n",
    "    ], dense_layers=[256]),\n",
    "    gamma=0.95, epsilon_start=1, epsilon_decay=0.99, epsilon_end=0.01, memory_size=10000, batch_size=64, target_update_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.curiosity import CuriosityDQNAgent\n",
    "\n",
    "dqn_factory = ConvQNetworkFactory(env, conv_layers=[\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    ], dense_layers=[256])\n",
    "\n",
    "agent_3 = CuriosityDQNAgent(env, dqn_factory, gamma=0.98, epsilon_start=1, epsilon_decay=0.995, epsilon_end=0.01, memory_size=50000,\n",
    "                                  batch_size=32, target_update_interval=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment with those parameters\n",
    "env.reset()\n",
    "\n",
    "# Setup random opponents\n",
    "agents = {drone.index: RandomAgent(env) for drone in env.drones}\n",
    "agents[0] = dqn_agent_1\n",
    "agents[1] = dqn_agent_2\n",
    "agents[2] = agent_3\n",
    "\n",
    "# Create trainer\n",
    "trainer = MultiAgentTrainer(env, agents, reset_agents=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in agents.values():\n",
    "    agent.is_greedy = False\n",
    "\n",
    "trainer.train(500)\n",
    "plot_rolling_rewards(trainer.rewards_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in agents.values():\n",
    "    agent.is_greedy = True\n",
    "\n",
    "rewards_log = test_agents(env, agents, n_steps=1000)\n",
    "plot_cumulative_rewards(rewards_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
