{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run env.py\n",
    "%run rl-helpers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-learning agent\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "obs_wrapper = GridView # Possible values: CompassQTable, LidarCompassQTable, GridView, BinaryGridView\n",
    "env = obs_wrapper(DeliveryDrones(n=5))\n",
    "states = env.reset()\n",
    "\n",
    "# Create agents\n",
    "agents = {drone.index: RandomAgent(env) for drone in env.drones}\n",
    "my_agent = QLearningAgent(\n",
    "    env, gamma=0.9, alpha=0.1, epsilon_start=1, epsilon_decay=0.98, epsilon_end=0.01)\n",
    "my_drone = env.drones[0]\n",
    "agents[my_drone.index] = my_agent\n",
    "\n",
    "# Train for a few steps, plot results\n",
    "trainer = MultiAgentTrainer(env, agents, seed=0)\n",
    "my_agent.is_greedy = False\n",
    "trainer.train(5000)\n",
    "plot_rolling_rewards(trainer.rewards_log, subset=range(1, 5))\n",
    "my_agent.get_qtable()\n",
    "\n",
    "# Test agents\n",
    "my_agent.is_greedy = True\n",
    "rewards_log = test_agents(env, agents, n_steps=1000, seed=0)\n",
    "plot_cumulative_rewards(rewards_log, subset=range(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test agents\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Make sure our drone behaves greedily\n",
    "my_drone.is_greedy = True\n",
    "\n",
    "# Simulation loop\n",
    "states = env.reset()\n",
    "rewards = None\n",
    "while True:\n",
    "    # Render\n",
    "    clear_output(wait=True)\n",
    "    print(env.render('ainsi'))\n",
    "\n",
    "    # Act\n",
    "    actions = {index: agent.act(states[index]) for index, agent in agents.items()}\n",
    "\n",
    "    # Print last rewards and next actions\n",
    "    print('Drone:', my_drone.index)\n",
    "    if hasattr(env, 'format_state'):\n",
    "        print('Current states:', env.format_state(states[my_drone.index]))\n",
    "    if hasattr(env, 'format_action'):\n",
    "        print('Next actions:', env.format_action(actions[my_drone.index]))\n",
    "    if rewards is not None:\n",
    "        print('Last rewards:', rewards[my_drone.index])\n",
    "\n",
    "    # Sleep, step, learn\n",
    "    time.sleep(0.5)\n",
    "    states, rewards, dones, _ = env.step(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create drones & environment\n",
    "env = GridView(DeliveryDrones(n=25))\n",
    "states = env.reset()\n",
    "\n",
    "# Run drones\n",
    "for _ in tqdm_notebook(range(10**6)):\n",
    "    env.step({drone.index: env.action_space.sample() for drone in env.drones})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development space below\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gym.spaces as spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run env.py\n",
    "%run rl-helpers.py\n",
    "\n",
    "# Create environment\n",
    "env = GridView(DeliveryDrones(n=5))\n",
    "states = env.reset()\n",
    "all_drones, all_drones_positions = env.air.get_objects(Drone)\n",
    "print('Drones:', all_drones, all_drones_positions)\n",
    "\n",
    "all_packets, all_packets_positions = env.ground.get_objects(Packet)\n",
    "print('Packets:', all_packets, all_packets_positions)\n",
    "\n",
    "all_dropzones, all_dropzones_positions = env.ground.get_objects(Dropzone)\n",
    "print('Dropzones:', all_dropzones, all_dropzones_positions)\n",
    "\n",
    "print('Drones packets:', [(d, d.packet) for d in all_drones])\n",
    "print(env.render(mode='ainsi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Drone, pickup, dropoff, collision ~Â simple geometric shapes\n",
    "# https://image.freepik.com/free-vector/simple-geometric-shapes-background_1168-371.jpg\n",
    "# Animation: slightly growing/shrinking to simulate up/down movement with shade\n",
    "\n",
    "# Desired output\n",
    "# https://img.deszone.net/2018/05/simple-geometric-shapes-free-vector-pattern4.jpg\n",
    "# https://as1.ftcdn.net/jpg/01/72/82/18/500_F_172821814_Oyl3cNYBcigDpeCzehbAQghLxJILrZA5.jpg\n",
    "\n",
    "# Other ideas\n",
    "# Drones leave a fading trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
