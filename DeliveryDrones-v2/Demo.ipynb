{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create environment and agents\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run env.py\n",
    "%run rl-helpers.py\n",
    "\n",
    "# Create environment:\n",
    "#   (Q-table) CompassQTable, CompassChargeQTable, LidarCompassQTable, LidarCompassChargeQTable\n",
    "#   (Grid)    WindowedGridView\n",
    "env = WindowedGridView(DeliveryDrones(), radius=3)\n",
    "\n",
    "# Create agent\n",
    "\"\"\"Q-learning agent\n",
    "my_agent = QLearningAgent(env, gamma=0.99, alpha=0.1, epsilon_start=1, epsilon_decay=0.99, epsilon_end=0.01)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"DQN with dense Q-network\n",
    "my_agent = DQNAgent(\n",
    "    env, DenseQNetworkFactory(env, hidden_layers=[256, 256]),\n",
    "    gamma=0.95, epsilon_start=0.5, epsilon_decay=0.8, epsilon_end=0.01, memory_size=10000, batch_size=64, target_update_interval=5)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"DQN with conv. Q-network\"\"\"\n",
    "my_agent = DQNAgent(\n",
    "    env, ConvQNetworkFactory(env, conv_layers=[\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "        {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1}\n",
    "    ], dense_layers=[256]),\n",
    "    gamma=0.95, epsilon_start=1, epsilon_decay=0.99, epsilon_end=0.01, memory_size=10000, batch_size=64, target_update_interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup custom environment parameters for training\n",
    "env.env_params.update({'n_drone': 3, 'pickup_reward': 1, 'discharge': 2})\n",
    "\n",
    "# Reset environment with those parameters\n",
    "env.reset()\n",
    "\n",
    "# Setup random opponents\n",
    "agents = {drone.index: RandomAgent(env) for drone in env.drones}\n",
    "agents[0] = my_agent\n",
    "\n",
    "# Create trainer\n",
    "trainer = MultiAgentTrainer(env, agents, reset_agents=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.is_greedy = False\n",
    "\n",
    "# Train with different grids\n",
    "for _ in range(10):\n",
    "    trainer.train(2000) # Calls env.reset() -> new grid\n",
    "    \n",
    "    # Reset epsilon\n",
    "    my_agent.epsilon_start *= 0.99\n",
    "    my_agent.epsilon = my_agent.epsilon_start\n",
    "\n",
    "plot_rolling_rewards(trainer.rewards_log, subset=range(0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect agents\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Q-learning agent\n",
    "if isinstance(my_agent, QLearningAgent):\n",
    "    # Q-table\n",
    "    print('Q-table:', my_agent.get_qtable().shape)\n",
    "    display(my_agent.get_qtable().sample(10))\n",
    "\n",
    "# For DQN-agent\n",
    "elif isinstance(my_agent, DQNAgent):\n",
    "    # Memory replay\n",
    "    my_agent.inspect_memory()\n",
    "    \n",
    "    # Q-network\n",
    "    print('Q-network:')\n",
    "    print(my_agent.qnetwork)\n",
    "    print()\n",
    "    \n",
    "# Epsilon decay\n",
    "plt.plot(my_agent.epsilons)\n",
    "plt.title('Epsilon decay')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Epsilon')\n",
    "plt.show()\n",
    "\n",
    "# Test with different seeds\n",
    "my_agent.is_greedy = True\n",
    "for i in range(10):\n",
    "    rewards_log = test_agents(env, agents, n_steps=1000, seed=i)\n",
    "    plot_cumulative_rewards(rewards_log, subset=range(0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test agents\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Make sure our drone behaves greedily\n",
    "my_agent.is_greedy = True\n",
    "\n",
    "# Simulation loop\n",
    "states = env.reset()\n",
    "my_drone = env.drones[0]\n",
    "rewards = None\n",
    "\n",
    "while True:\n",
    "    # Render\n",
    "    clear_output(wait=True)\n",
    "    print(env.render('ainsi'))\n",
    "\n",
    "    # Act\n",
    "    actions = {index: agent.act(states[index]) for index, agent in agents.items()}\n",
    "\n",
    "    # Print last rewards and next actions\n",
    "    print('Drone:', my_drone.index, 'charge: {}%'.format(my_drone.charge))\n",
    "    if hasattr(env, 'format_state'):\n",
    "        print('Current states:', env.format_state(states[my_drone.index]))\n",
    "    if hasattr(env, 'format_action'):\n",
    "        print('Next actions:', env.format_action(actions[my_drone.index]))\n",
    "    if rewards is not None:\n",
    "        print('Last rewards:', rewards[my_drone.index])\n",
    "\n",
    "    # Sleep, step, learn\n",
    "    time.sleep(1)\n",
    "    states, rewards, dones, _ = env.step(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run env.py\n",
    "%run rl-helpers.py\n",
    "\n",
    "# Create drones & environment\n",
    "env = WindowedGridView(DeliveryDrones(env_params={'n_drones': 10+1}), radius=3)\n",
    "states = env.reset()\n",
    "\n",
    "# Run drones\n",
    "for i in tqdm(range(10**6)):\n",
    "    states, rewards, dones, _  = env.step({drone.index: env.action_space.sample() for drone in env.drones})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RGBA image\n",
    "sprites_img = Image.open('16ShipCollection.png')\n",
    "sprites_img_array = np.array(sprites_img)\n",
    "\n",
    "# Make black background transparent\n",
    "black_pixels = (sprites_img_array[:, :, 0] + sprites_img_array[:, :, 1] + sprites_img_array[:, :, 2]) == 0\n",
    "sprites_img_array[np.nonzero(black_pixels) + (3,)] = 0\n",
    "\n",
    "# Create tiles\n",
    "def get_ships_tile(row, col):\n",
    "    tiles_size, small_padding, big_padding = 16, 4, 10\n",
    "    top_corner = (42, 28)\n",
    "    \n",
    "    i = top_corner[0] + row*(tiles_size+small_padding)\n",
    "    j = top_corner[1] + (col%5)*(tiles_size+small_padding) + (col//5) * (5*(tiles_size+small_padding) + big_padding)\n",
    "    return Image.fromarray(sprites_img_array[i:i+tiles_size, j:j+tiles_size])\n",
    "\n",
    "tiles = {\n",
    "    'packet': get_ships_tile(11, 9),\n",
    "    'dropzone': get_ships_tile(11, 8),\n",
    "    'station': get_ships_tile(18, 15),\n",
    "    'skyscraper': get_ships_tile(18, 12)\n",
    "}\n",
    "\n",
    "drones_iter = itertools.product([1, 6, 15, 13, 7, 8, 16, 0, 2, 3, 4, 5, 9, 10, 13, 17], [0, 1, 2, 3, 4])\n",
    "for index, (i, j) in enumerate(drones_iter):\n",
    "    label = 'drone_{}'.format(index)\n",
    "    tiles[label] = get_ships_tile(i, j)\n",
    "    tiles[label + '_packet'] = get_ships_tile(i, j+10) # red\n",
    "    tiles[label + '_charging'] = Image.alpha_composite(tiles['dropzone'], get_ships_tile(i, j+15)) # overlay + yellow\n",
    "    tiles[label + '_over_dropzone'] = Image.alpha_composite(tiles['dropzone'], get_ships_tile(i, j)) # overlay\n",
    "\n",
    "# Create empty frame\n",
    "render_padding, tiles_size = 8, 16\n",
    "frames_size = tiles_size * env.shape[0] + render_padding * (env.shape[0] + 1)\n",
    "empty_frame = np.full(shape=(frames_size, frames_size, 4), fill_value=0, dtype=np.uint8)\n",
    "empty_frame[:, :, 3] = 255 # Remove background transparency\n",
    "    \n",
    "# Render frame\n",
    "frame = Image.fromarray(empty_frame.copy())\n",
    "for i in range(env.shape[0]):\n",
    "    for j in range(env.shape[1]):\n",
    "        # Check tile\n",
    "        ground = env.ground[i, j]\n",
    "        air = env.air[i, j]\n",
    "        \n",
    "        if (air is None) and (ground is None):\n",
    "            continue # Nothing to draw\n",
    "        \n",
    "        if air is None:\n",
    "            if isinstance(ground, Packet):\n",
    "                tile = tiles['packet']\n",
    "            elif isinstance(ground, Dropzone):\n",
    "                tile = tiles['dropzone']\n",
    "            elif isinstance(ground, Station):\n",
    "                tile = tiles['station']\n",
    "            elif isinstance(ground, Skyscraper):\n",
    "                tile = tiles['skyscraper']\n",
    "        else:\n",
    "            # If air is not None, then it's a drone\n",
    "            drone = air\n",
    "            \n",
    "            if drone.packet is None:\n",
    "                if ground == None:\n",
    "                    tile = tiles['drone_{}'.format(drone.index)]\n",
    "                elif isinstance(ground, Station):\n",
    "                    tile = tiles['drone_{}_charging'.format(drone.index)]\n",
    "                elif isinstance(ground, Dropzone):\n",
    "                    tile = tiles['drone_{}_over_dropzone'.format(drone.index)]\n",
    "            else:\n",
    "                tile = tiles['drone_{}_packet'.format(drone.index)]\n",
    "        \n",
    "        # Paste tile on frame\n",
    "        tile_x = j*tiles_size + (j+1)*render_padding\n",
    "        tile_y = i*tiles_size + (i+1)*render_padding\n",
    "        frame.paste(tile, (tile_x, tile_y), mask=tile)\n",
    "\n",
    "# Rescale frame\n",
    "rescale = lambda old_size: int(old_size * 1)\n",
    "frame.resize(size=(rescale(frame.size[0]), rescale(frame.size[1])), resample=Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.render(mode='ainsi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "-- combinations --\n",
    "with_packet = red (col+10)\n",
    "drone_charging = overlay + yellow (col+15)\n",
    "drone_charging_with_packet = nothing\n",
    "drone_over_dropzone = overlay\n",
    "\n",
    "-- Nice to have: events --\n",
    "just_delivered = drone + (.., ..)\n",
    "just crashed = (.., ..) / drone + (.., ..) # debris?\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
